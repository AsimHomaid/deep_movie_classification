{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = pymongo.MongoClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = mc['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_features_db = db['labels_deep_features']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set number of frames and genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_frames = deep_features_db.count_documents({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = ['Action', 'Adventure', 'Animation', 'Biography', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Family', 'Fantasy', 'Film-Noir','Game-Show','History','Horror','Music','Musical','Mystery','News','Reality-TV','Romance','Sci-Fi','Short','Sport','Thriller','War','Western']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## given the large dataset, a single dataframe cannot load it. So a set of empty numpy arrays are made to be later filled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_ids = [str(i) for i in range(2048)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_ids = np.empty(shape=(n_frames,), dtype=np.object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_features = np.empty(shape=(n_frames, 2048), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_genres = np.empty(shape=(n_frames, len(genres)), dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop that fills out the arrays above by each mongo document. Needs to be done manually like this in order not to fill computer memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in enumerate(deep_features_db.find({})):\n",
    "    for feature_id in feature_ids:\n",
    "        frame_features[i, int(feature_id)] = row[feature_id]\n",
    "    frame_ids[i] = row['frame_id']\n",
    "    for j, genre in enumerate(genres):\n",
    "        frame_genres[i, j] = row[genre]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arrays store frames with movie title, train test split must be done by movie titles in order not mix test frames from the same movie with train frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_movie(frame_ids, frame_features, frame_genres, train_pct=0.8, limit=None):\n",
    "    n = len(frame_ids)\n",
    "    frame_titles = np.array([frame_id.partition('_')[0] for frame_id in frame_ids], dtype=np.object)\n",
    "\n",
    "    movie_titles = np.array(list(set(frame_titles)))\n",
    "    movie_titles\n",
    "    np.random.shuffle(movie_titles)\n",
    "\n",
    "    train_limit = int(len(movie_titles)*train_pct)\n",
    "\n",
    "    train_titles = movie_titles[:train_limit]\n",
    "    test_titles = movie_titles[train_limit:]\n",
    "\n",
    "    test_mask = np.isin(frame_titles, test_titles)\n",
    "    train_mask = ~test_mask\n",
    "    \n",
    "    if limit is not None:\n",
    "        idxs = np.arange(n)\n",
    "        np.random.shuffle(idxs)\n",
    "        keep_idxs = idxs[:limit]\n",
    "        keep_mask = np.zeros(n, dtype=bool)\n",
    "        keep_mask[keep_idxs] = True\n",
    "        test_mask = test_mask & keep_mask\n",
    "        train_mask = train_mask & keep_mask\n",
    "\n",
    "    X_train = frame_features[train_mask, :]\n",
    "    y_train = frame_genres[train_mask, :]\n",
    "    X_test = frame_features[test_mask, :]\n",
    "    y_test = frame_genres[test_mask, :]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split_by_movie(frame_ids, \n",
    "                                                  frame_features,\n",
    "                                                  frame_genres,\n",
    "                                                  train_pct=0.8,\n",
    "                                                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import random forest, train on dataset, then export model as pickle to use in deployment.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename = 'finalized_model.sav'\n",
    "pickle.dump(rfc, open(filename, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
